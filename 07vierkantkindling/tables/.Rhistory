my.df[my.df$Var1 == c("2009","2010"),]
my.df[my.df$Var1 == c("2009","2010", "2011"),]
my.df[my.df$Var1 == c("2009","2010"),]
ggplot(my.df, aes(Var1, Freq, fill = Var2)) + geom_bar() +
scale_colour_brewer("DVCS Host",palette = 2, type = "qual") +
xlab("Year") + ylab("PMC article disclosure")
ggplot(my.df, aes(Var1, Freq, fill = Var2)) + geom_bar(stat="bin") +
scale_colour_brewer("DVCS Host",palette = 2, type = "qual") +
xlab("Year") + ylab("PMC article disclosure")
ggplot(my.df, aes(Var1, Freq, fill = Var2)) + geom_bar(stat="identity") +
scale_colour_brewer("DVCS Host",palette = 2, type = "qual") +
xlab("Year") + ylab("PMC article disclosure")
ggplot(my.df, aes(Var1, Freq, fill = Var2)) + geom_bar(stat="identity") +
scale_fill_brewer("DVCS Host",palette = 2, type = "qual") +
xlab("Year") + ylab("PMC article disclosure")
ggplot(my.df, aes(Var1, Freq, fill = Var2)) + geom_bar(stat="identity") +
scale_fill_brewer("DVCS Host",palette = 2, type = "qual") +
xlab("Year") + ylab("PMC article disclosure") + theme_blank()
ggplot(my.df, aes(Var1, Freq, fill = Var2)) + geom_bar(stat="identity") +
scale_fill_brewer("DVCS Host",palette = 2, type = "qual") +
xlab("Year") + ylab("PMC article disclosure") + theme_bw()
ggplot(my.df, aes(Var1, Freq, fill = Var2)) + geom_bar(stat="identity") +
scale_colour_brewer("DVCS Host",palette = 2, type = "qual") +
xlab("Year") + ylab("PMC article disclosure") + title("kdkd")
ggplot(my.df, aes(Var1, Freq, fill = Var2)) + geom_bar(stat="identity") +
scale_colour_brewer("DVCS Host",palette = 2, type = "qual") +
xlab("Year") + ylab("PMC article disclosure") + title("kdkd")
ggplot(my.df, aes(Var1, Freq, fill = Var2)) + geom_bar(stat="identity") +
scale_colour_brewer("DVCS Host",palette = 2, type = "qual") +
xlab("Year") + ylab("PMC article disclosure")
ggplot(my.df, aes(Var1, Freq, fill = Var2)) + geom_bar(stat="identity") +
scale_fill_brewer("DVCS Host",palette = 2, type = "qual") +
xlab("Year") + ylab("PMC article disclosure") + theme_bw() +
labs(title="Annual growth OA Gold by Publisher")
ggplot(my.df, aes(Var1, Freq, fill = Var2)) + geom_bar(stat="identity") +
scale_fill_brewer("DVCS Host",palette = 2, type = "qual") +
xlab("Year") + ylab("PMC article disclosure") + theme_bw() +
labs(title="Data and Code Disclosure in Collaborative DVCS facilities")
ggsave(p, file = "plotDVCS.pdf", height = 8/2.54, width = 18/2.54)
p <- ggplot(my.df, aes(Var1, Freq, fill = Var2)) + geom_bar(stat="identity") +
scale_fill_brewer("DVCS Host",palette = 2, type = "qual") +
xlab("Year") + ylab("PMC article disclosure") + theme_bw() +
labs(title="Data and Code Disclosure in Collaborative DVCS facilities")
ggsave(p, file = "plotDVCS.pdf", height = 8/2.54, width = 18/2.54)
my.data <- my.data[my.data$pubYear > 2008, ]
my.data$.id <- factor(my.data$.id, levels = c(rownames(data.frame(rev(sort(table(my.data$.id)))))))
my.df <- data.frame(as.matrix(table(unlist(my.data$pubYear), my.data$.id)))
my.df
p <- ggplot(my.df, aes(Var1, Freq, fill = Var2)) + geom_bar(stat="identity") +
scale_fill_brewer("DVCS Host",palette = 2, type = "qual") +
xlab("Year") + ylab("PMC article disclosure") + theme_bw() +
labs(title="Data and Code Disclosure in Collaborative DVCS facilities")
ggsave(p, file = "plotDVCS.pdf", height = 8/2.54, width = 18/2.54)
p <- ggplot(my.df, aes(Var1, Freq, fill = Var2)) + geom_bar(stat="identity") +
scale_fill_brewer("DVCS Host",palette = 2, type = "qual") +
xlab("Year Published") + ylab("Europe PMC full text articles") + theme_bw() +
labs(title="Data and Code Disclosure in Collaborative DVCS facilities")
ggsave(p, file = "plotDVCS.pdf", height = 8/2.54, width = 18/2.54)
getwd()
u.pub <- "http://pub.uni-bielefeld.de/person/9618254"
tt <- content(GET(u.pub, add_headers(Accept = "application/json")))
tt.records <- tt$records
require(httr)
require(jsonlite)
u.pub <- "http://pub.uni-bielefeld.de/person/9618254"
tt <- content(GET(u.pub, add_headers(Accept = "application/json")))
tt.records <- tt$records
tt.records <- sapply(tt.records, "[[", "record")
tt.ama <- unlist(sapply(record, "[[", "citation")[c("ama"),])
tt.id <- unlist(sapply(record, "[[", "_id"))
tt.df <- paste(tt.ama, '<br><a href="',tt.id,'">PUB</a>', sep ="")
cat(sprintf("<li>%s</li>", tt.df))
u.pub <- "http://pub.uni-bielefeld.de/person/9618254"
tt <- content(GET(u.pub, add_headers(Accept = "application/json")))
tt.records <- tt$records
tt.records <- sapply(tt.records, "[[", "record")
tt.ama <- unlist(sapply(tt.records, "[[", "citation")[c("ama"),])
tt.id <- unlist(sapply(tt.records, "[[", "_id"))
tt.df <- paste(tt.ama, '<br><a href="',tt.id,'">PUB</a>', sep ="")
cat(sprintf("<li>%s</li>", tt.df))
tt <- content(GET(u.git, add_headers(Accept = "application/json")))
u.git <- "https://api.github.com/users/hbuschme/repos"
tt <- content(GET(u.git, add_headers(Accept = "application/json")))
tt
summary(tt)
tt[1]
tt[[1]]
names(tt[[1]])
to.parse <- c("name", "html_url", "owner", "description", "created_at", "updated_at","pushed_at", "git_url", "ssh_url", "clone_url", "svn_url", "size", "stargazers_count", "watchers_count", "forks_count")
sapply(tt, "[[", to.parse)
sapply(tt, "[", to.parse)
lapply(tt, "[", to.parse)
ldply(tt, "[", to.parse)
library(plyr)
do.call("rbind", lapply(tt, "[", to.parse))
tt.df
head(git.parsed)
git.parsed <- do.call("rbind", lapply(tt, "[", to.parse))
head(git.parsed)
paste(git.parsed$sv_url, "kk", sep"")
paste(git.parsed$svn_url, "kk", sep"")
paste(git.parsed$svn_url, "kk", sep="")
git.parsed <- do.call("rbind", lapply(tt, "[", to.parse))
git.parsed$svn_url
git.parsed
is(git.parsed)
git.parsed <- data.frame(do.call("rbind", lapply(tt, "[", to.parse)))
git.parsed$svn_url
git.parsed <- do.call("rbind", lapply(tt, "[", to.parse))
git.parsed <- data.frame(do.call("rbind", lapply(tt, "[", to.parse)))
sprintf("<li>%s</li>,git.parsed)
)
""
""
sprintf("<li>%s</li>", git.parsed)
sprintf("<li>%s</li>", git.parsed$size)
sprintf("<li>%s</li>", git.parsed[1,])
git.parsed$size
paste("ahhaha",git.parsed$size, "kksks", sep="")
require(httr)
require(jsonlite)
u.git <- "https://api.github.com/users/hbuschme/repos"
tt <- content(GET(u.git, add_headers(Accept = "application/json")))
summary(tt)
git.parsed <- data.frame(do.call("rbind", lapply(tt, "[", to.parse)))
to.parse <- c("name", "html_url", "owner", "description", "created_at", "updated_at","pushed_at", "git_url", "ssh_url", "clone_url", "svn_url", "size", "stargazers_count", "watchers_count", "forks_count")
git.parsed <- data.frame(do.call("rbind", lapply(tt, "[", to.parse)))
git.parsed
paste('<a href="', git.parsed$html_url, '">', git.parsed$name)
paste('<a href="', git.parsed$html_url, '">', git.parsed$name, sep="")
title.git <- paste('<a href="', git.parsed$html_url, '">', git.parsed$name, sep="")
sprintf('<i>%s</s>', git.parsed$description)
time.git <- paste('created at: ', created_at, ' | updated at: ', updated at, ' | Pushed at: ', pushed_at, sep="")
paste("created at:", created_at, " | updated at: ", updated at, " | Pushed at: ", pushed_at, sep="")
paste("created at:", created_at, " | updated at: ", updated_at, " | Pushed at: ", pushed_at, sep="")
paste("created at:", git.parsed$created_at, " | updated at: ", git.parsed$updated_at, " | Pushed at: ", git.parsed$pushed_at, sep="")
title.git <- paste('<a href="', git.parsed$html_url, '">', git.parsed$name, sep="")
time.git <- paste("created at:", git.parsed$created_at, " | updated at: ", git.parsed$updated_at, " | Pushed at: ", git.parsed$pushed_at, sep="")
description <- sprintf('<i>%s</i>', git.parsed$description)
cat(title.git, git.parsed, description, "<br>")
is(time.git)
is(description)
is(title.git)
cat(title.git, git.parsed, description, "<br>")
time.git
apply(git.parsed, 1, paste('<a href="', git.parsed$html_url, '">', git.parsed$name, sep="")
)
apply(git.parsed, 1, function(x) paste('<a href="', x$html_url, '">', x$name, sep="")
)
apply(git.parsed, 1, function(x) paste('<a href="', x$html_url, '">', x$name, sep=""),
paste("created at:",x$created_at, " | updated at: ", x$updated_at, " | Pushed at: ", x$pushed_at, sep="")
)
apply(git.parsed, 1, function(x) paste('<a href="', x$html_url, '">', x$name, sep=""), function(x)
paste("created at:",x$created_at, " | updated at: ", x$updated_at, " | Pushed at: ", x$pushed_at, sep="")
)
apply(git.parsed, 1, function(x) paste('<a href="', x$html_url, '">', x$name, '</a><br>',
"created at:",x$created_at, " | updated at: ", x$updated_at, " | Pushed at: ", x$pushed_at, '<br>GIT: <a href=', git_url, '>', git_url, '</a><br>', sep="")
)
apply(git.parsed, 1, function(x) paste('<a href="', x$html_url, '">', x$name, '</a><br>',
'created at:' ,x$created_at, ' | updated at: ', x$updated_at, ' | Pushed at: ', x$pushed_at, '<br>GIT: <a href="', git_url, '">', git_url, '</a><br>', sep="")
)
u.git <- "https://api.github.com/users/hbuschme/repos"
apply(git.parsed, 1, function(x) paste('<a href="', x$html_url, '">', x$name, '</a><br>',
'created at:' ,x$created_at, ' | updated at: ', x$updated_at, ' | Pushed at: ', x$pushed_at, '<br>GIT: <a href="', x$git_url, '">', x$git_url, '</a><br>', sep="")
)
sprintf(tt.html, "<p>%s</p>")
tt.html <- apply(git.parsed, 1, function(x) paste('<a href="', x$html_url, '">', x$name, '</a><br>',
'created at:' ,x$created_at, ' | updated at: ', x$updated_at, ' | Pushed at: ', x$pushed_at, '<br>GIT: <a href="', x$git_url, '">', x$git_url, '</a><br>', sep=""))
sprintf(tt.html, "<p>%s</
)
)))
)))""")"
tt.html <- apply(git.parsed, 1, function(x) paste('<a href="', x$html_url, '">', x$name, '</a><br>',
'created at:' ,x$created_at, ' | updated at: ', x$updated_at, ' | Pushed at: ', x$pushed_at, '<br>GIT: <a href="', x$git_url, '">', x$git_url, '</a><br>', sep=""))
sprintf(tt.html, "<p>%s</p>")
tt.html <- apply(git.parsed, 1, function(x) paste('<a href="', x$html_url, '">', x$name, '</a><br>',
'created at:' ,x$created_at, ' | updated at: ', x$updated_at, ' | Pushed at: ', x$pushed_at, '<br>GIT: <a href="', x$git_url, '">', x$git_url, '</a><br>', sep=""))
sprintf(tt.html, "<p> %s </p>")
?sprintf
is(tt.html)
tt.html <- apply(git.parsed, 1, function(x) paste('<a href="', x$html_url, '">', x$name, '</a><br>',
'created at:' ,x$created_at, ' | updated at: ', x$updated_at, ' | Pushed at: ', x$pushed_at, '<br>GIT: <a href="', x$git_url, '">', x$git_url, '</a><br>', sep=""))
sprintf("<p>%s</p>", tt.html)
tt.html <- apply(git.parsed, 1, function(x) paste('<a href="', x$html_url, '">', x$name, '</a><br>',
'created at:' ,x$created_at, ' | updated at: ', x$updated_at, ' | Pushed at: ', x$pushed_at, '<br>GIT: <a href="', x$git_url, '">', x$git_url, '</a><br>', sep=""))
sprintf("<p>%s</p>", tt.html)
tt.html <- apply(git.parsed, 1, function(x) paste('<a href="', x$html_url, '">', x$name, '</a><br>', '<i>', x$description, '</i><br>', created at:' ,x$created_at, ' | updated at: ', x$updated_at, ' | Pushed at: ', x$pushed_at, '<br>GIT: <a href="', x$git_url, '">', x$git_url, '</a><br>', sep=""))
tt.html <- apply(git.parsed, 1, function(x) paste('<a href="', x$html_url, '">', x$name, '</a><br>', '<i>', x$description, '</i><br>', 'created at:' ,x$created_at, ' | updated at: ', x$updated_at, ' | Pushed at: ', x$pushed_at, '<br>GIT: <a href="', x$git_url, '">', x$git_url, '</a><br>', sep=""))
cat(sprintf("<li>%s</li>", tt.html))
git.parsed
head(tt)
u.pub <- "http://pub.uni-bielefeld.de/person/9618254"
tt <- content(GET(u.pub, add_headers(Accept = "application/json")))
unlist(sapply(tt.records, "[[", "citation")[c("ama"),])
tt.records <- sapply(tt.records, "[[", "record")
u.pub <- "http://pub.uni-bielefeld.de/person/9618254"
tt <- content(GET(u.pub, add_headers(Accept = "application/json")))
tt.records <- tt$records
tt.records <- sapply(tt.records, "[[", "record")
tt.ama <- unlist(sapply(tt.records, "[[", "citation")[c("ama"),])
unlist(sapply(tt.records, "[[", "citation")[c("ama"),])
unlist(sapply(tt.records, "[[", "doi")
)
unlist(sapply(tt.records, "[[", "externalIdentifier")[c("doi),])
)
)
""
))")"
unlist(sapply(tt.records, "[[", "externalIdentifier")[c("doi"),])
unlist(sapply(tt.records, "[[", "externalIdentifier"))
unlist(sapply(tt.records, "[[", "doiInfo"))
unlist(sapply(tt.records, "[[", "doiInfo")[c("doi"),])
unlist(sapply(tt.records, "[[", "doiInfo"))
unlist(sapply(tt.records, "[[", "doiInfo"))["doi"]
unlist(sapply(tt.records, "[[", "doiInfo"))["doi",]
unlist(sapply(tt.records, "[[", "doiInfo"))[c("doi"),]
unlist(sapply(tt.records, "[[", "doiInfo"))[,c("doi")]
unlist(sapply(tt.records, "[[", "doiInfo"))[[("doi")]|
test <- (sapply(tt.records, "[[", "doiInfo"))
sapply(test,"[",]"doi")
sapply(test,"[", "doi")
unlist(sapply(test,"[", "doi"))
data.frame(unlist(sapply(test,"[", "doi"))
)
tt.id <- unlist(sapply(tt.records, "[[", "_id"))
data.frame(unlist(sapply(test,"[", "doi"))
, tt.id)
tt
u.git <- "https://api.github.com/users/hbuschme/repos"
tt <- content(GET(u.git, add_headers(Accept = "application/json")))
to.parse <- c("name", "html_url", "owner", "description", "created_at", "updated_at","pushed_at", "git_url", "ssh_url", "clone_url", "svn_url", "size", "stargazers_count", "watchers_count", "forks_count")
tt.owner <- tt$owner
tt
tt[[1]]$owner
cat(sprintf('<p><img href="%s"></p>', tt[[1]]$owner$$avatar_url))
cat(sprintf('<p><img href="%s"></p>', tt[[1]]$owner$avatar_url))
u.data <- "http://pub.uni-bielefeld.de/person/9618254?style=ama&fmt=json"
content(GET(u.data))
u.data
u.data <- "http://pub.uni-bielefeld.de/person/9618254?style=ama&fmt=json"
u.data
content(GET(u.data))
u.data
u.data <- "http://pub.uni-bielefeld.de/data?style=ama&fmt=json&person=9618254"
content(GET(u.data))
tt.data <- content(GET(u.data))
u.data <- "http://pub.uni-bielefeld.de/data?style=ama&fmt=json&person=9618254"
tt.data <- content(GET(u.data))
tt.records <- tt.data$records
tt.records <- sapply(tt.records, "[[", "record")
tt.ama <- unlist(sapply(tt.records, "[[", "citation")[c("ama"),])
tt.records <- tt.data$records
tt.records <- sapply(tt.records, "[[", "record")
tt.ama <- unlist(sapply(tt.records, "[[", "citation")[c("ama"),])
tt.records <- sapply(tt.records, "[[", "record")
tt.data <- content(GET(u.data))
tt.records <- tt.data$records
tt.records <- sapply(tt.records, "[[", "record")
unlist(sapply(tt.records, "[[", "citation")[c("ama"),])
unlist(sapply(tt.records, "[[", "citation")
)
tt.records
tt.records$citation
tt.data <- content(GET(u.data))
tt.records <- tt.data$records
tt.records
tt.records <- sapply(tt.records, "[[", "record")
tt.records
(tt.records, "[[", "citation")
sapply(tt.records, "[[", "citation")
sapply(tt.records, "[", "citation")
tt.records <- tt.data$records
tt.records <- lapply(tt.records, "[[", "record")tt.records <- tt.data$records
tt.records <- lapply(tt.records, "[[", "record")
tt.records
unlist(sapply(tt.records, "[[", "citation")[c("ama"),])
u.pub <- "http://pub.uni-bielefeld.de/person/9618254"
tt <- content(GET(u.pub, add_headers(Accept = "application/json")))
tt.records <- tt$records
length(tt.records)
doaj <- read.csv("http://www.doaj.org/doaj?func=csv", header = TRUE, sep=",")
#subset social science journals
doaj.soz <- doaj[grep("Social Science",doaj$Subjects),]
View(doaj.soz)
doaj.soz <- doaj[grep("Sociology (General)",doaj$Subjects),]
table(doaj.soz$CC.License)
doaj <- read.csv("http://www.doaj.org/doaj?func=csv", header = TRUE, sep=",")
doaj.soz <- doaj[grep("Sociology (General)",doaj$Subjects),]
head(doaj.soz)
head(doaj)
doaj.soz <- doaj[grep("Sociology",doaj$Subjects),]
dim(doaj)
length(unique(doaj$ISSN))
doaj[duplicated(doaj$ISSN),]
doaj[duplicated(doaj$ISSN),"Title"]
View(doaj)
doaj[duplicated(doaj$ISSN),]
doaj[duplicated(doaj$ISSN),"ISSN"]
require(rebi)
require(devtools)
install_github("rebi", "ropensci")
require(rebi)
my.df <- search_publications(query = 'AUTHORID:"0000-0002-7635-3473"')
?get_author
my.data <- ldply(id, get_author)
library(plyr)
my.data <- ldply(id, get_author)
id <- c('24352233', '23928564')
my.data <- ldply(id, get_author)
# tabulate ORCIDs
table(my.data$authorId.value)
getwd()
get_external <- function(base.url = NA, id = NA, externalID = "ISI") {
#CURL Option
ch <- getCurlHandle()
curlSetOpt(curl = ch,
ssl.verifypeer = FALSE)
#arguments for API call as list
.args <- list()
.args$version <- "1.1"
.args$operation <- "searchRetrieve"
.args$query <- paste("id", id, sep="=")
#call
doc <- xmlTreeParse(getForm(base.url, .params = .args), useInternal = T)
tt.path <- paste("//r:relatedItem[@type='host']//r:identifier[@type='", externalID, "']", sep="")
external <- xpathSApply(doc, tt.path,
namespaces = (c(r = "http://www.loc.gov/mods/v3")) ,xmlValue)
if (length(external) == 0) {
external <- "notFound"
} else { external <- external}
data.frame(id, externalID, external)
}
#' Get publication records funded by Bielefeld University Publishing Fund
#' @import RCurl, XML
#' @param base.url SRU base URL
#' @param query CQL quer
#' @return data.frame with id, title, journal title, year published, reference (frontShort)
#' @examples \dontrun{
#' my.data <- search_sru(base.url = "http://pub.uni-bielefeld.de/sru", fundedby ="fundedbyubi")
#' }
search_sru <- function(base.url = NA, query = NA) {
#CURL Option
ch <- getCurlHandle()
curlSetOpt(curl = ch,
ssl.verifypeer = FALSE)
#arguments for API call as list
.args <- list()
.args$version <- "1.1"
.args$operation <- "searchRetrieve"
.args$maximumRecords <- 1000
.args$query <- query
#call
doc <- xmlTreeParse(getForm(base.url, .params = .args), useInternal = T)
#number of records
numberOfRecords <- xpathSApply(doc,"//r:numberOfRecords",
namespaces = (c(r = "http://www.loc.gov/zing/srw/")) ,xmlValue)
sru.call <- function(x) {
.args$startRecord = x
doc <- xmlTreeParse(getForm(base.url, .params = .args), useInternal = T)
id <- xpathSApply(doc,"//r:recordIdentifier",
namespaces = (c(r = "http://www.loc.gov/mods/v3")) ,xmlValue)
year <- xpathSApply(doc,"//r:dateIssued",
namespaces= (c(r="http://www.loc.gov/mods/v3")) ,xmlValue)
reference <- xpathSApply(doc,"//r:extension//r:bibliographicCitation//r:ama",
namespaces= (c(r="http://www.loc.gov/mods/v3")) ,xmlValue)
genre <- xpathSApply(doc,"//r:genre",
namespaces= (c(r="http://www.loc.gov/mods/v3")) ,xmlValue)
tt <- data.frame(id, year, genre, reference)
return(tt)
}
my.data <- do.call("rbind",
lapply(seq(1, as.numeric(numberOfRecords), by = 1000), sru.call))
my.data$query <- query
return(my.data)
}
my.data <- search_sru(base.url = "http://pub.uni-bielefeld.de/sru", query = "publishingYear>2008")
library(RCurl)
library(XML)
my.data <- search_sru(base.url = "http://pub.uni-bielefeld.de/sru", query = "publishingYear>2008")
my.data$year <- format(as.Date(my.data$year, format ="%Y"), "%Y")
my.data <- my.data[my.data$year %in% c("2009", "2010", "2011", "2012", "2013", "2014"),]
my.data$genre <- factor (my.data$genre, levels = c(rownames(data.frame(rev(
sort(table(my.data$genre)))))))
my.table <- dcast(my.data, genre ~ year, margins =T, drop =F)
lirbary(plyr)
library(plyr)
my.table <- dcast(my.data, genre ~ year, margins =T, drop =F)
library(reshape)
my.table <- dcast(my.data, genre ~ year, margins =T, drop =F)
library(reshape2)
my.table <- dcast(my.data, genre ~ year, margins =T, drop =F)
my.table
head(my.table)
library(gpglot2)
library(ggplot2)
ggplot(my.data, aes(year, genre)) + geom_bar(=)
ggplot(my.data, aes(year, genre)) + geom_bar()
p <- ggplot(df,aes(x=factor(year),y=..count..,fill=factor(genre)))+geom_bar() #basic
p <- p + ylab("No. of Publications") + xlab ("Publishing Year") # Axis
p + opts (title = "CITEC Publications in PUB")
ggsave("CITEC2008-11.png")
p
ggplot(my.data, aes(year)) + geom_bar(stat="bin")
p <- ggplot(my.data, aes(year)) + geom_bar(stat="bin") #basic
p <- p + ylab("No. of Publications") + xlab ("Publishing Year") # Axis
p
p <- ggplot(my.data, aes(year, fill = genre)) + geom_bar(stat="bin") #basic
p
my.data$genre <- factor(my.data$genre,
levels =  c(rownames(data.frame(rev(sort(table(my.data$genre)))))))
levels(my.data$genre)[6:length(levels(my.data$genre))] <- paste("other (n=",
length(unique(my.data$genre)) - 5, ")", sep="")
p <- ggplot(my.data, aes(year, fill = genre)) + geom_bar(stat="bin") #basic
p <- p + ylab("No. of Publications") + xlab ("Publishing Year") # Axis
p
p + scale_y_continuous(limits=c(0, 3000)) +
scale_fill_brewer(type="qual", palette = 1) + theme_bw()
theme
p <- p + theme(legend.position="top", legend.text = element_text(size = 6, colour = "black"))
p
p <- p + scale_y_continuous(limits=c(0, 3000)) +  scale_fill_brewer(type="qual", palette = 1) + theme_bw()
p
p <- ggplot(my.data, aes(year, fill = genre)) + geom_bar(stat="bin") #basic
p <- p + ylab("No. of Publications") + xlab ("Publishing Year") # Axis
p <- p + scale_y_continuous(limits=c(0, 3000)) +  scale_fill_brewer(type="qual", palette = 1) + theme_bw()
p <- p + theme(legend.position="top", legend.text = element_text(size = 6, colour = "black"))
p
p <- p + theme(legend.position="top", legend.text = element_text(size = 12, colour = "black"))
p
ggsave(p, file = "pubAll.png", width=6.8,height=4.5,units="in")
p <- p + theme(legend.position="top", legend.text = element_text(size = 10, colour = "black"))
ggsave(p, file = "pubAll.png", width=6.8,height=4.5,units="in")
my.data.oa <- search_sru(base.url = "http://pub.uni-bielefeld.de/sru", query = "publishingYear>2008 AND fulltext=1")
head(my.data.od)
head(my.data.oa)
table(my.data$year)
table(my.data.oa$year)
my.data$OA <- my.data$id <- my.data.oa$id
head(my.data)
my.data$OA <- my.data$id %in% my.data.oa$id
head(my.data)
table(my.dataoa$OA)
table(my.data.oa$OA)
my.data$OA <- my.data.oa$id %in% my.data$id
table(my.data.oa$OA)
my.data$OA <- my.data$id %in% my.data.oa$id
table(my.data$OA)
pub.journal <- my.data[my.data$genre == "article",]
arxiv <- lapply(pub.journal$id, get_external, base.url="http://pub.uni-bielefeld.de/sru",externalID ="arXiv")
medline <- lapply(pub.journal$id, get_external, base.url="http://pub.uni-bielefeld.de/sru",externalID ="MEDLINE")
pub.t <- read.csv("sourcePUB.csv", header F, sep=",")
pub.t <- read.csv("sourcePUB.csv", header = F, sep=",")
pub.t
dim(pub.journal)
pub.t / 6507
pub.t / 6507 * 100
pub.t <- read.csv("sourcePUB.csv", header = F, sep=",")
pub.t / 6507 * 100
pub.t$V2 / 6507 * 100
pub.t$perc <- pub.t$V2 / 6507 * 100
pub.t$perc
pub.t
ggplot(pub.tm aes(V1, perc)) + geom_bar()
ggplot(pub.t, aes(V1, perc)) + geom_bar()
ggplot(pub.t, aes(V1, perc)) + geom_bar(stat=identity)
ggplot(pub.t, aes(V1, perc)) + geom_bar(stat="identity")
ggplot(pub.t, aes(V1, perc)) + geom_bar(stat="identity") + coord_flip()
ggplot(pub.t, aes(V1, perc)) + geom_bar(stat="identity") + coord_flip() + theme_bw()
ggplot(pub.t, aes(V1, perc)) + geom_bar(stat="identity") + coord_flip() + theme_bw() + scale_fill_manual("red")
ggplot(pub.t, aes(V1, perc)) + geom_bar(stat="identity") + coord_flip() + theme_bw() + scale_fill_manual(values=c("red"))
ggplot(pub.t, aes(V1, perc, fill ="red")) + geom_bar(stat="identity") + coord_flip() + theme_bw()
ggplot(pub.t, aes(V1, perc, fill ="green
")) + geom_bar(stat="identity") + coord_flip() + theme_bw()
ggplot(pub.t, aes(V1, perc)) + geom_bar(stat="identity", fill="#FF9999") + coord_flip() + theme_bw()
ggplot(pub.t, aes(V1, perc)) + geom_bar(stat="identity", fill="#789aa1") + coord_flip() + theme_bw()
ggplot(pub.t, aes(V1, perc)) + geom_bar(stat="identity", fill="#789aa1") + coord_flip() + theme_bw() + xlab("Import Source") +
ylab("Coverage Journal Articles 2009 - 2014")
ggplot(pub.t, aes(V1, perc)) + geom_bar(stat="identity", fill="#789aa1") + coord_flip() + theme_bw() + xlab("Import Source") +
ylab("Coverage Journal Articles 2009 - 2014 in Percent") +  scale_y_continuous(limits=c(0, 70))
ggplot(pub.t, aes(V1, perc)) + geom_bar(stat="identity", fill="#789aa1") + coord_flip() + theme_bw() + xlab("Import Source") +
ylab("Coverage Journal Articles 2009 - 2014 in Percent") +  scale_y_continuous(limits=c(0, 80))
ggsave(p, file = "pubSource.png", width=6.8,height=4.5,units="in")
q <- ggplot(pub.t, aes(V1, perc)) + geom_bar(stat="identity", fill="#789aa1") + coord_flip() + theme_bw() + xlab("Import Source") +
ylab("Coverage Journal Articles 2009 - 2014 in Percent") +  scale_y_continuous(limits=c(0, 80))
ggsave(q, file = "pubSource.png", width=6.8,height=4.5,units="in")
getwd()
setwd("~/Documents/libreasgit/ausgabe26/07vierkantkindling/tables")
library(xtable)
?xtable
?list.files
x <- list.files(*.csv)
x <- list.files(path ="*.csv")
x
x <- list.files()
x
read_convert <- function(x) {
my.table <- read.csv(x, header =T, sep = ",")
print(xtable(my.table), include.rownames =FALSE, file= paste(x, ".tex", sep=""), type="html")
}
sapply(x, read_convert)
x <- list.files()
read_convert <- function(x) {
my.table <- read.csv(x, header =T, sep = ",")
print(xtable(my.table), include.rownames =FALSE, file= paste(x, ".tex", sep=""), type="html")
}
sapply(x, read_convert)
x <- list.files()
read_convert <- function(x) {
my.table <- read.csv(x, header =T, sep = ",")
print(xtable(my.table), include.rownames =FALSE, file= paste(x, ".html", sep=""), type="html")
}
sapply(x, read_convert)
